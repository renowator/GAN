{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-19469394bd66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, BatchNormalization, Activation, UpSampling2D, Conv2D, Reshape, Dropout, Flatten\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras import optimizers, losses, initializers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 156800)            15836800  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 156800)            627200    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 156800)            0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 280, 280, 2)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 560, 560, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 187, 187, 100)     3300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 187, 187, 100)     400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 187, 187, 100)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 63, 63, 50)        45050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 63, 63, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 63, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 3)         153       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 16,513,103\n",
      "Trainable params: 16,199,203\n",
      "Non-trainable params: 313,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Generator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Build Generative model ...\n",
    "        g_input = Input(shape=[100])\n",
    "        H = Dense(200*28*28)(g_input)\n",
    "        H = BatchNormalization()(H)\n",
    "        H = Activation('relu')(H)\n",
    "        H = Reshape( [280,280, 2] )(H)\n",
    "        H = UpSampling2D(size=(2, 2))(H)\n",
    "        H = Conv2D(100, kernel_size=4, strides=3, padding='same')(H)\n",
    "        H = BatchNormalization()(H)\n",
    "        H = Activation('relu')(H)\n",
    "        H = Conv2D(50, 3, strides=3, padding='same')(H)\n",
    "        H = BatchNormalization()(H)\n",
    "        H = Activation('relu')(H)\n",
    "        H = Conv2D(3, 1, strides=2, padding='same')(H)\n",
    "        #H = UpSampling2D(size=(2, 2))(H)\n",
    "        g_V = Activation('sigmoid')(H)\n",
    "        self.model = Model(g_input,g_V)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam())\n",
    "    def forward(self, inputs):\n",
    "        return self.model.predict(inputs)\n",
    "generator = Generator()\n",
    "generator.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 256)       19456     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 11,685,889\n",
      "Trainable params: 11,685,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Discriminator():\n",
    "    def __init__(self):# Build Discriminative model ...\n",
    "        d_input = Input(shape=[32,32,3])\n",
    "        dropout_rate = 0.25\n",
    "        H = Conv2D(256, (5, 5), strides=(2, 2), padding = 'same', activation='relu')(d_input)\n",
    "        H = Activation('relu')(H)\n",
    "        H = Dropout(dropout_rate)(H)\n",
    "        H = Conv2D(512, (5, 5), strides=(2, 2), padding = 'same', activation='relu')(H)\n",
    "        H = Activation('relu')(H)\n",
    "        H = Dropout(dropout_rate)(H)\n",
    "        H = Flatten()(H)\n",
    "        H = Dense(256)(H)\n",
    "        H = Activation('relu')(H)\n",
    "        H = Dropout(dropout_rate)(H)\n",
    "        d_V = Dense(1)(H)\n",
    "        self.model = Model(d_input,d_V)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam())\n",
    "    def forward(self, inputs):\n",
    "        return self.model.predict(inputs)\n",
    "discriminator = Discriminator()\n",
    "discriminator.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot generated Images\n",
    "def plot_gen(n_ex=16,dim=(5,5), figsize=(10,10) ):\n",
    "    noise = np.random.uniform(0,1,size=[5,100])\n",
    "    generated_images = generator.forward(noise)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    print(generated_images.shape)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = np.zeros([32,32,3])\n",
    "        #print(img.shape)\n",
    "        img[:,:,0] = 255*generated_images[i,:,:,0]\n",
    "        img[:,:,1] = 255*generated_images[i,:,:, 1]\n",
    "        img[:,:,2] = 255*generated_images[i,:,:, 2]\n",
    "        print(img[:,:,0].shape)\n",
    "        plt.imshow(img.astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "    #plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 32, 3)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAACACAYAAAArgTx9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable batch_normalization_1/moving_mean/biased already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1012, in moving_average_update\n    x, value, momentum, zero_debias=True)\n  File \"/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/layers/normalization.py\", line 195, in call\n    self.momentum),\n  File \"/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2b54e886688f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build stacked GAN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgan_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#gan_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#gan_V = discriminator.model(H)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#GAN = Model(gan_input, gan_V)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m    722\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                             output_masks = layer.compute_mask(computed_tensor,\n\u001b[1;32m    726\u001b[0m                                                               computed_mask)\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    193\u001b[0m         self.add_update([K.moving_average_update(self.moving_mean,\n\u001b[1;32m    194\u001b[0m                                                  \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                                                  self.momentum),\n\u001b[0m\u001b[1;32m    196\u001b[0m                          K.moving_average_update(self.moving_variance,\n\u001b[1;32m    197\u001b[0m                                                  \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mmoving_average_update\u001b[0;34m(x, value, momentum)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \"\"\"\n\u001b[1;32m   1011\u001b[0m     return moving_averages.assign_moving_average(\n\u001b[0;32m-> 1012\u001b[0;31m         x, value, momentum, zero_debias=True)\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/tensorflow/python/training/moving_averages.py\u001b[0m in \u001b[0;36massign_moving_average\u001b[0;34m(variable, value, decay, zero_debias, name)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mzero_debias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mupdate_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_zero_debias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mupdate_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/tensorflow/python/training/moving_averages.py\u001b[0m in \u001b[0;36m_zero_debias\u001b[0;34m(unbiased_var, value, decay)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mlocal_step_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       biased_var = variable_scope.get_variable(\n\u001b[0;32m--> 180\u001b[0;31m           \"biased\", initializer=biased_initializer, trainable=False)\n\u001b[0m\u001b[1;32m    181\u001b[0m       local_step = variable_scope.get_variable(\n\u001b[1;32m    182\u001b[0m           \u001b[0;34m\"local_step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    662\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 664\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable batch_normalization_1/moving_mean/biased already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1012, in moving_average_update\n    x, value, momentum, zero_debias=True)\n  File \"/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/layers/normalization.py\", line 195, in call\n    self.momentum),\n  File \"/Users/nickstepanov/miniconda3/envs/RoboND/lib/python3.5/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build stacked GAN model\n",
    "gan_input = Input(shape=[100])\n",
    "H = generator.model(Input(shape=[100]))#gan_input)\n",
    "#gan_V = discriminator.model(H)\n",
    "#GAN = Model(gan_input, gan_V)\n",
    "#GAN.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(), metics = ['binary_crossentropy'])\n",
    "#GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image as PImage\n",
    "from os import listdir\n",
    "import scipy.misc\n",
    "def loadImages(path):\n",
    "    # return array of images\n",
    "\n",
    "    imagesList = listdir(path)\n",
    "   \n",
    "    loadedImages = []\n",
    "    for image in imagesList:\n",
    "        if image != '.DS_Store':\n",
    "            img = cv2.imread(path + image)\n",
    "            loadedImages.append(img.copy())\n",
    "            img.load()\n",
    "            img.close()\n",
    "            \n",
    "    return loadedImages\n",
    "\n",
    "path = \"/Users/nickstepanov/GAN/EmojiOne/\"\n",
    "\n",
    "# your images in an array\n",
    "def real_imgs():\n",
    "    imgs = loadImages(path)\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for img in imgs:\n",
    "        # you can show every image\n",
    "        print(img[0])\n",
    "        pix = scipy.misc.imresize(np.array(img.getdata()).reshape(img.size[0], img.size[1], 3),(32,32))\n",
    "        X_train.append(pix)\n",
    "        Y_train.append(1)\n",
    "    X_train = np.array(X_train)\n",
    "    X_train = X_train/255.\n",
    "    Y_train = np.array(Y_train)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Discriminator on True dataset\n",
    "def train_disc(X,Y,epochs=5):\n",
    "    while epochs>0:\n",
    "        print (\"Epochs on discriminator left: %d \"%(epochs))\n",
    "        discriminator.model.fit(X,Y, batch_size=32)\n",
    "        epochs = epochs - 1\n",
    "def disc_pred(X):\n",
    "    return discriminator.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate Fake dataset\n",
    "def gen_fake():\n",
    "    X_fake = []\n",
    "    Y_fake = []\n",
    "    numP = 10\n",
    "    img = generator.forward(np.random.uniform(0,1,size=[numP,100]))\n",
    "    X_fake = np.array(img)\n",
    "    X_fake = X_fake/255.\n",
    "\n",
    "    for i in range(numP):\n",
    "        Y_fake.append(0)\n",
    "    return np.array(X_fake), np.array(Y_fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(X,Y):\n",
    "    y_hat = discriminator.forward(X)\n",
    "    y_hat_idx = np.argmax(y_hat,axis=1)\n",
    "    y_idx = np.argmax(Y,axis=0)\n",
    "    diff = y_idx-y_hat_idx\n",
    "    n_tot = X_train.shape[0]\n",
    "    n_rig = (diff==0).sum()\n",
    "    acc = n_rig*100.0/n_tot\n",
    "    print (\"Accuracy: %0.02f pct (%d of %d) right\"%(acc, n_rig, n_tot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze weights in the discriminator for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.model.layers:\n",
    "        l.trainable = val\n",
    "    net.model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam())\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      "Generate fake imgs\n",
      "Train on fake imgs\n",
      "Epochs on discriminator left: 5 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 2s - loss: 15.9424\n",
      "Epochs on discriminator left: 4 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 0s - loss: 15.9424\n",
      "Epochs on discriminator left: 3 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 0s - loss: 15.9424\n",
      "Epochs on discriminator left: 2 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 0s - loss: 15.9424\n",
      "Epochs on discriminator left: 1 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 0s - loss: 15.9424\n",
      "Train on real imgs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-68ca7048f97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-68ca7048f97c>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m        \u001b[0mtrain_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train on real imgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m        \u001b[0mtrain_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m        \u001b[0mnoise_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1028\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-a73af870df88>\u001b[0m in \u001b[0;36mreal_imgs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# your images in an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreal_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-a73af870df88>\u001b[0m in \u001b[0;36mloadImages\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimagesList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloadedImages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    " # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "def plot_loss(losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(losses[\"d\"], label='discriminitive loss_a')\n",
    "    plt.plot(losses[\"r\"], label='discriminitive loss_b')\n",
    "    plt.plot(losses[\"g\"], label='generative loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def train_gan(epochs=5):\n",
    "    losses = {\"d\":[], \"g\":[], \"r\":[]}\n",
    "    for i in range(epochs):\n",
    "        print (\"Epoch: %d \"%(i))\n",
    "        make_trainable(discriminator,True)\n",
    "        print(\"Generate fake imgs\")\n",
    "        X, Y = gen_fake()\n",
    "        print(\"Train on fake imgs\")\n",
    "        train_disc(X,Y)\n",
    "        print(\"Train on real imgs\")\n",
    "        X, Y = real_imgs()\n",
    "        train_disc(X,Y)\n",
    "        noise_tr = np.random.uniform(0,1,size=[1028,100])\n",
    "        y2 = np.zeros([1028,1])\n",
    "        #y2 = discriminator.forward(generator.forward(noise_tr))   \n",
    "        y2 = np.array([1] * 1028)\n",
    "        make_trainable(discriminator,False)\n",
    "        callback = keras.callbacks.ProgbarLogger(count_mode='samples')\n",
    "        g_loss = GAN.fit_generator(noise_tr, y2 , epochs = 5, verbose = 1,callbacks = callback)\n",
    "        losses[\"g\"].append(g_loss)\n",
    "        plot_gen()\n",
    "    plot_loss(losses)\n",
    "    \n",
    "\n",
    "\n",
    "train_gan(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 0.00196188,  0.00196006,  0.00195882],\n",
       "          [ 0.00196257,  0.00195939,  0.00196116],\n",
       "          [ 0.00196152,  0.00195709,  0.0019609 ],\n",
       "          ..., \n",
       "          [ 0.0019633 ,  0.00196031,  0.00195812],\n",
       "          [ 0.00196186,  0.00196018,  0.00195877],\n",
       "          [ 0.00196029,  0.00196143,  0.00195994]],\n",
       " \n",
       "         [[ 0.0019622 ,  0.00196036,  0.00196005],\n",
       "          [ 0.00195912,  0.00195944,  0.00195943],\n",
       "          [ 0.00196041,  0.00195847,  0.00195802],\n",
       "          ..., \n",
       "          [ 0.00196191,  0.00195654,  0.00196095],\n",
       "          [ 0.00196233,  0.00195699,  0.00195856],\n",
       "          [ 0.00196148,  0.00195916,  0.00195797]],\n",
       " \n",
       "         [[ 0.00195956,  0.00196007,  0.00195865],\n",
       "          [ 0.00195984,  0.00195742,  0.0019584 ],\n",
       "          [ 0.0019597 ,  0.00195861,  0.00196145],\n",
       "          ..., \n",
       "          [ 0.00196332,  0.00195772,  0.00195865],\n",
       "          [ 0.00196184,  0.00195781,  0.00196028],\n",
       "          [ 0.00196033,  0.00195959,  0.00195999]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196062,  0.00196068,  0.00195983],\n",
       "          [ 0.00195854,  0.00195446,  0.00195597],\n",
       "          [ 0.00196231,  0.00195872,  0.00195984],\n",
       "          ..., \n",
       "          [ 0.0019622 ,  0.00195947,  0.00196205],\n",
       "          [ 0.00195811,  0.00195843,  0.00195847],\n",
       "          [ 0.00196155,  0.00196051,  0.00196053]],\n",
       " \n",
       "         [[ 0.00196127,  0.00196033,  0.00195945],\n",
       "          [ 0.00196226,  0.00196005,  0.00196007],\n",
       "          [ 0.00195942,  0.00195779,  0.00196207],\n",
       "          ..., \n",
       "          [ 0.00195793,  0.00195574,  0.00196128],\n",
       "          [ 0.00196138,  0.00195944,  0.00196079],\n",
       "          [ 0.00195984,  0.0019597 ,  0.00195777]],\n",
       " \n",
       "         [[ 0.00196073,  0.00195987,  0.00195989],\n",
       "          [ 0.00196362,  0.00196004,  0.00196085],\n",
       "          [ 0.00196288,  0.0019605 ,  0.0019615 ],\n",
       "          ..., \n",
       "          [ 0.0019589 ,  0.00195955,  0.0019605 ],\n",
       "          [ 0.00196187,  0.00195977,  0.00196056],\n",
       "          [ 0.00196177,  0.00196004,  0.00196017]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00196078,  0.00195955,  0.00195939],\n",
       "          [ 0.00196237,  0.00195826,  0.0019611 ],\n",
       "          [ 0.00196025,  0.00195864,  0.00196046],\n",
       "          ..., \n",
       "          [ 0.00196259,  0.00196086,  0.00195931],\n",
       "          [ 0.00196081,  0.00195847,  0.00196005],\n",
       "          [ 0.00196061,  0.00195962,  0.0019595 ]],\n",
       " \n",
       "         [[ 0.00196049,  0.00196039,  0.0019593 ],\n",
       "          [ 0.00195669,  0.00195727,  0.00195916],\n",
       "          [ 0.00196086,  0.0019592 ,  0.00195917],\n",
       "          ..., \n",
       "          [ 0.00196045,  0.00195855,  0.00195971],\n",
       "          [ 0.00196101,  0.0019584 ,  0.00196029],\n",
       "          [ 0.00196002,  0.00195959,  0.00195929]],\n",
       " \n",
       "         [[ 0.00196085,  0.00195951,  0.00195884],\n",
       "          [ 0.00195881,  0.00195801,  0.00196104],\n",
       "          [ 0.00195879,  0.00195765,  0.00196131],\n",
       "          ..., \n",
       "          [ 0.00196368,  0.00195696,  0.00196016],\n",
       "          [ 0.00195866,  0.00195781,  0.00195891],\n",
       "          [ 0.0019603 ,  0.00195902,  0.00196094]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.0019603 ,  0.00195913,  0.00196011],\n",
       "          [ 0.00196098,  0.00195755,  0.00195725],\n",
       "          [ 0.00195956,  0.00195883,  0.0019591 ],\n",
       "          ..., \n",
       "          [ 0.00196089,  0.00195917,  0.00196089],\n",
       "          [ 0.00195897,  0.00195999,  0.00195948],\n",
       "          [ 0.00196144,  0.0019598 ,  0.001958  ]],\n",
       " \n",
       "         [[ 0.0019617 ,  0.00196007,  0.00195972],\n",
       "          [ 0.00196076,  0.00196042,  0.00195864],\n",
       "          [ 0.00196008,  0.00195631,  0.00196134],\n",
       "          ..., \n",
       "          [ 0.00195952,  0.00195672,  0.00196   ],\n",
       "          [ 0.00196361,  0.00195974,  0.00196151],\n",
       "          [ 0.00196059,  0.00196013,  0.00195819]],\n",
       " \n",
       "         [[ 0.00196175,  0.00196194,  0.00195973],\n",
       "          [ 0.00196055,  0.00195858,  0.00196136],\n",
       "          [ 0.00196177,  0.00195995,  0.001962  ],\n",
       "          ..., \n",
       "          [ 0.00195913,  0.0019607 ,  0.00196031],\n",
       "          [ 0.00196322,  0.00196094,  0.00196153],\n",
       "          [ 0.00196079,  0.00195984,  0.00196   ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00196188,  0.00195995,  0.00195976],\n",
       "          [ 0.00196237,  0.00195876,  0.00196145],\n",
       "          [ 0.00196274,  0.00195859,  0.00196095],\n",
       "          ..., \n",
       "          [ 0.0019606 ,  0.00195934,  0.00195861],\n",
       "          [ 0.00196198,  0.00196059,  0.00196067],\n",
       "          [ 0.00196173,  0.00196084,  0.00195979]],\n",
       " \n",
       "         [[ 0.00196251,  0.00195927,  0.00196125],\n",
       "          [ 0.00195773,  0.00195712,  0.00196026],\n",
       "          [ 0.00196187,  0.00195973,  0.00195828],\n",
       "          ..., \n",
       "          [ 0.00196067,  0.00195783,  0.00195909],\n",
       "          [ 0.00196207,  0.0019581 ,  0.00195846],\n",
       "          [ 0.00196159,  0.00196002,  0.00195832]],\n",
       " \n",
       "         [[ 0.00196168,  0.00195929,  0.00195924],\n",
       "          [ 0.00195973,  0.00195681,  0.00195976],\n",
       "          [ 0.00195878,  0.00195799,  0.00196101],\n",
       "          ..., \n",
       "          [ 0.0019614 ,  0.00195847,  0.00195928],\n",
       "          [ 0.00196056,  0.00195914,  0.00195986],\n",
       "          [ 0.00195989,  0.00195867,  0.00195946]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196109,  0.00196024,  0.00195924],\n",
       "          [ 0.00196294,  0.00195775,  0.00195612],\n",
       "          [ 0.00196308,  0.00195977,  0.00196065],\n",
       "          ..., \n",
       "          [ 0.00196044,  0.00195771,  0.00196097],\n",
       "          [ 0.00196029,  0.00195888,  0.00195858],\n",
       "          [ 0.00196009,  0.00195843,  0.00195798]],\n",
       " \n",
       "         [[ 0.00196196,  0.0019603 ,  0.00195919],\n",
       "          [ 0.00196061,  0.00195784,  0.00195725],\n",
       "          [ 0.00196077,  0.0019582 ,  0.00195975],\n",
       "          ..., \n",
       "          [ 0.00195909,  0.0019551 ,  0.00196136],\n",
       "          [ 0.00196512,  0.00196049,  0.00196051],\n",
       "          [ 0.00196005,  0.00196031,  0.00195894]],\n",
       " \n",
       "         [[ 0.00196305,  0.00196257,  0.00195866],\n",
       "          [ 0.00196319,  0.0019594 ,  0.00196129],\n",
       "          [ 0.00196274,  0.00196146,  0.00196186],\n",
       "          ..., \n",
       "          [ 0.00195944,  0.00196062,  0.0019595 ],\n",
       "          [ 0.00196224,  0.00196039,  0.00196232],\n",
       "          [ 0.00196129,  0.00195883,  0.00196056]]],\n",
       " \n",
       " \n",
       "        ..., \n",
       "        [[[ 0.00196138,  0.00195966,  0.00195881],\n",
       "          [ 0.00196248,  0.00195876,  0.0019617 ],\n",
       "          [ 0.0019627 ,  0.00195998,  0.00196147],\n",
       "          ..., \n",
       "          [ 0.00196217,  0.0019606 ,  0.00195968],\n",
       "          [ 0.00196089,  0.00195848,  0.00195978],\n",
       "          [ 0.00196234,  0.00196052,  0.00196067]],\n",
       " \n",
       "         [[ 0.00196157,  0.00196031,  0.00195973],\n",
       "          [ 0.00195746,  0.0019585 ,  0.00195936],\n",
       "          [ 0.001961  ,  0.00195891,  0.00195754],\n",
       "          ..., \n",
       "          [ 0.00196198,  0.00195764,  0.00196193],\n",
       "          [ 0.00196277,  0.00195714,  0.00196017],\n",
       "          [ 0.00196049,  0.00195847,  0.00195941]],\n",
       " \n",
       "         [[ 0.00196099,  0.00195956,  0.00195871],\n",
       "          [ 0.00196012,  0.00195737,  0.00196042],\n",
       "          [ 0.00196004,  0.00195589,  0.00196219],\n",
       "          ..., \n",
       "          [ 0.00196272,  0.00195842,  0.00195887],\n",
       "          [ 0.00195997,  0.00195876,  0.00196014],\n",
       "          [ 0.00196076,  0.00196021,  0.00195919]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196032,  0.00195976,  0.00195981],\n",
       "          [ 0.0019607 ,  0.00195529,  0.00195759],\n",
       "          [ 0.00195993,  0.00195984,  0.0019592 ],\n",
       "          ..., \n",
       "          [ 0.00196095,  0.0019587 ,  0.00196148],\n",
       "          [ 0.00195724,  0.00195725,  0.00195746],\n",
       "          [ 0.00196073,  0.00195954,  0.00195952]],\n",
       " \n",
       "         [[ 0.00196057,  0.0019602 ,  0.0019597 ],\n",
       "          [ 0.00196119,  0.0019592 ,  0.00196021],\n",
       "          [ 0.00196002,  0.00195763,  0.00196268],\n",
       "          ..., \n",
       "          [ 0.00196034,  0.00195846,  0.00196178],\n",
       "          [ 0.00196442,  0.00195968,  0.00196114],\n",
       "          [ 0.00196069,  0.00195996,  0.00195898]],\n",
       " \n",
       "         [[ 0.00196211,  0.00196203,  0.00196001],\n",
       "          [ 0.00196069,  0.00195827,  0.00196139],\n",
       "          [ 0.00196049,  0.00196089,  0.00196216],\n",
       "          ..., \n",
       "          [ 0.00195926,  0.00196039,  0.00196094],\n",
       "          [ 0.00196261,  0.00196028,  0.00196103],\n",
       "          [ 0.00196139,  0.00195928,  0.00196048]]],\n",
       " \n",
       " \n",
       "        [[[ 0.001962  ,  0.00196024,  0.00195861],\n",
       "          [ 0.0019613 ,  0.00195954,  0.00195972],\n",
       "          [ 0.00196273,  0.00195945,  0.0019613 ],\n",
       "          ..., \n",
       "          [ 0.00196294,  0.00196045,  0.00195883],\n",
       "          [ 0.0019625 ,  0.00195778,  0.00196128],\n",
       "          [ 0.00196162,  0.00196062,  0.00196004]],\n",
       " \n",
       "         [[ 0.00196076,  0.00196016,  0.00195935],\n",
       "          [ 0.00195882,  0.00195762,  0.00195948],\n",
       "          [ 0.00196101,  0.00195894,  0.00195898],\n",
       "          ..., \n",
       "          [ 0.00196124,  0.00195701,  0.0019624 ],\n",
       "          [ 0.00196139,  0.00195728,  0.00195983],\n",
       "          [ 0.00196129,  0.00195996,  0.00195858]],\n",
       " \n",
       "         [[ 0.00195985,  0.00196009,  0.00195978],\n",
       "          [ 0.0019599 ,  0.00195745,  0.00196035],\n",
       "          [ 0.00195823,  0.00195838,  0.0019615 ],\n",
       "          ..., \n",
       "          [ 0.00196506,  0.00195962,  0.00196087],\n",
       "          [ 0.00196249,  0.00195826,  0.00195997],\n",
       "          [ 0.00195954,  0.00195907,  0.00196059]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196071,  0.00196033,  0.00196033],\n",
       "          [ 0.00195857,  0.00195531,  0.00195684],\n",
       "          [ 0.00196255,  0.00195909,  0.00196133],\n",
       "          ..., \n",
       "          [ 0.00196188,  0.00195935,  0.00196169],\n",
       "          [ 0.0019591 ,  0.00195788,  0.00196016],\n",
       "          [ 0.00196019,  0.00195844,  0.0019596 ]],\n",
       " \n",
       "         [[ 0.00196172,  0.00196085,  0.00195927],\n",
       "          [ 0.00195988,  0.00195998,  0.00195983],\n",
       "          [ 0.00196101,  0.00195785,  0.00196214],\n",
       "          ..., \n",
       "          [ 0.00195919,  0.00195691,  0.00196118],\n",
       "          [ 0.00196131,  0.00195906,  0.0019606 ],\n",
       "          [ 0.00196048,  0.00196084,  0.00196049]],\n",
       " \n",
       "         [[ 0.00196033,  0.00196117,  0.00195896],\n",
       "          [ 0.00196203,  0.00196032,  0.00196041],\n",
       "          [ 0.00196175,  0.00196069,  0.00196122],\n",
       "          ..., \n",
       "          [ 0.00196016,  0.00195983,  0.00196112],\n",
       "          [ 0.00196295,  0.00196081,  0.00196159],\n",
       "          [ 0.00196211,  0.00196015,  0.00196105]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00196118,  0.00196002,  0.0019591 ],\n",
       "          [ 0.00196178,  0.00195867,  0.00196119],\n",
       "          [ 0.00196188,  0.0019604 ,  0.00196   ],\n",
       "          ..., \n",
       "          [ 0.0019627 ,  0.00196102,  0.00195988],\n",
       "          [ 0.00196104,  0.00195821,  0.00195975],\n",
       "          [ 0.00196154,  0.00195998,  0.00196003]],\n",
       " \n",
       "         [[ 0.00196165,  0.0019601 ,  0.00195976],\n",
       "          [ 0.0019576 ,  0.00195829,  0.00195907],\n",
       "          [ 0.00196049,  0.00195836,  0.00195916],\n",
       "          ..., \n",
       "          [ 0.00196066,  0.00195861,  0.00195862],\n",
       "          [ 0.00196144,  0.00195657,  0.00195905],\n",
       "          [ 0.00196049,  0.00195947,  0.00196014]],\n",
       " \n",
       "         [[ 0.00196062,  0.00195962,  0.00195943],\n",
       "          [ 0.00196024,  0.00195887,  0.00195952],\n",
       "          [ 0.00196031,  0.00195864,  0.00196104],\n",
       "          ..., \n",
       "          [ 0.00196392,  0.00195915,  0.00195979],\n",
       "          [ 0.00196127,  0.00195883,  0.00195907],\n",
       "          [ 0.00195914,  0.00195933,  0.00195987]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196074,  0.00196007,  0.00196015],\n",
       "          [ 0.00195919,  0.00195838,  0.00195682],\n",
       "          [ 0.00196017,  0.00195854,  0.00195917],\n",
       "          ..., \n",
       "          [ 0.00196115,  0.0019582 ,  0.00196032],\n",
       "          [ 0.0019604 ,  0.00195741,  0.00196032],\n",
       "          [ 0.00196048,  0.00195907,  0.00195983]],\n",
       " \n",
       "         [[ 0.00196168,  0.00196007,  0.00196011],\n",
       "          [ 0.00196114,  0.00195843,  0.0019599 ],\n",
       "          [ 0.00195877,  0.00195654,  0.00196076],\n",
       "          ..., \n",
       "          [ 0.00195952,  0.00195792,  0.00196029],\n",
       "          [ 0.00196336,  0.001959  ,  0.00196121],\n",
       "          [ 0.00196064,  0.00196092,  0.00195966]],\n",
       " \n",
       "         [[ 0.00196102,  0.00196135,  0.00196   ],\n",
       "          [ 0.00196281,  0.00195895,  0.00196044],\n",
       "          [ 0.00196245,  0.00195922,  0.00196215],\n",
       "          ..., \n",
       "          [ 0.00196022,  0.00196085,  0.0019608 ],\n",
       "          [ 0.00196163,  0.00196035,  0.00196103],\n",
       "          [ 0.00196199,  0.00196051,  0.00196049]]]], dtype=float32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_fake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
