{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-19469394bd66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, BatchNormalization, Activation, UpSampling2D, Conv2D, Reshape, Dropout, Flatten\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras import optimizers, losses, initializers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 156800)            15836800  \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 156800)            627200    \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 156800)            0         \n",
      "_________________________________________________________________\n",
      "reshape_23 (Reshape)         (None, 280, 280, 2)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_43 (UpSampling (None, 560, 560, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 187, 187, 100)     3300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 187, 187, 100)     400       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 187, 187, 100)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 63, 63, 50)        45050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 63, 63, 50)        200       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 63, 63, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 32, 32, 3)         153       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 16,513,103\n",
      "Trainable params: 16,199,203\n",
      "Non-trainable params: 313,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Generator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Build Generative model ...\n",
    "        g_input = Input(shape=[100])\n",
    "        H = Dense(200*28*28)(g_input)\n",
    "        H = BatchNormalization()(H)\n",
    "        H = Activation('relu')(H)\n",
    "        H = Reshape( [280,280, 2] )(H)\n",
    "        H = UpSampling2D(size=(2, 2))(H)\n",
    "        H = Conv2D(100, kernel_size=4, strides=3, padding='same')(H)\n",
    "        H = BatchNormalization()(H)\n",
    "        H = Activation('relu')(H)\n",
    "        H = Conv2D(50, 3, strides=3, padding='same')(H)\n",
    "        H = BatchNormalization()(H)\n",
    "        H = Activation('relu')(H)\n",
    "        H = Conv2D(3, 1, strides=2, padding='same')(H)\n",
    "        #H = UpSampling2D(size=(2, 2))(H)\n",
    "        g_V = Activation('sigmoid')(H)\n",
    "        self.model = Model(g_input,g_V)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam())\n",
    "    def forward(self, inputs):\n",
    "        return self.model.predict(inputs)\n",
    "generator = Generator()\n",
    "generator.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 16, 16, 256)       19456     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 8, 8, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 11,685,889\n",
      "Trainable params: 11,685,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Discriminator():\n",
    "    def __init__(self):# Build Discriminative model ...\n",
    "        d_input = Input(shape=[32,32,3])\n",
    "        dropout_rate = 0.25\n",
    "        H = Conv2D(256, (5, 5), strides=(2, 2), padding = 'same', activation='relu')(d_input)\n",
    "        H = LeakyReLU(0.2)(H)\n",
    "        H = Dropout(dropout_rate)(H)\n",
    "        H = Conv2D(512, (5, 5), strides=(2, 2), padding = 'same', activation='relu')(H)\n",
    "        H = LeakyReLU(0.2)(H)\n",
    "        H = Dropout(dropout_rate)(H)\n",
    "        H = Flatten()(H)\n",
    "        H = Dense(256)(H)\n",
    "        H = LeakyReLU(0.2)(H)\n",
    "        H = Dropout(dropout_rate)(H)\n",
    "        d_V = Dense(1,activation='softmax')(H)\n",
    "        self.model = Model(d_input,d_V)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam())\n",
    "    def forward(self, inputs):\n",
    "        return self.model.predict(inputs)\n",
    "discriminator = Discriminator()\n",
    "discriminator.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot generated Images\n",
    "def plot_gen(n_ex=16,dim=(5,5), figsize=(10,10) ):\n",
    "    noise = np.random.uniform(0,1,size=[5,100])\n",
    "    generated_images = generator.forward(noise)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    print(generated_images.shape)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        img = np.zeros([32,32,3])\n",
    "        #print(img.shape)\n",
    "        img[:,:,0] = 255*generated_images[i,:,:,0]\n",
    "        img[:,:,1] = 255*generated_images[i,:,:, 1]\n",
    "        img[:,:,2] = 255*generated_images[i,:,:, 2]\n",
    "        print(img[:,:,0].shape)\n",
    "        plt.imshow(img.astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "    #plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 32, 3)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAB/CAYAAADy1/bXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAAodJREFUeJzt3EEKwjAUQEErHjw3jxsXbioPpI2VmQOkgRB4/EC3OecNAIDP7qs3AABwBaIJACAQTQAAgWgCAAhEEwBAIJoAAALRBAAQiCYAgOBx5sfGGP6kucAYYztgTWe5wBFn+VrXeS7gbv4Pd/O/7J2nSRMAQCCaAACCU5/n4CvvQ+pDBuEAsM+kCQAgEE0AAIHnOa7DkxwAC5k0AQAEogkAIBBNAACBaAIACEQTAEAgmgAAAtEEABCIJgCAQDQBAASiCQAgEE0AAIFoAgAIRBMAQCCaAAAC0QQAEIgmAIBANAEABKIJACAQTQAAgWgCAAhEEwBAIJoAAALRBAAQiCYAgEA0AQAEogkAIBBNAACBaAIACEQTAEAgmgAAAtEEABCIJgCAQDQBAASiCQAgEE0AAIFoAgAIRBMAQCCaAAAC0QQAEIgmAIBANAEABKIJACAQTQAAgWgCAAhEEwBAIJoAAALRBAAQiCYAgEA0AQAEogkAIBBNAACBaAIACEQTAEAgmgAAAtEEABCIJgCAQDQBAASiCQAgEE0AAIFoAgAIRBMAQCCaAAAC0QQAEIgmAIBANAEABKIJACAQTQAAgWgCAAhEEwBAIJoAAALRBAAQiCYAgEA0AQAEogkAIBBNAACBaAIACEQTAEAgmgAAAtEEABCIJgCAQDQBAASiCQAgEE0AAIFoAgAIRBMAQCCaAAAC0QQAEGxzztV7AAD4eSZNAACBaAIACEQTAEAgmgAAAtEEABCIJgCAQDQBAASiCQAgEE0AAIFoAgAIRBMAQCCaAAAC0QQAEIgmAIBANAEABKIJACAQTQAAgWgCAAhEEwBAIJoAAALRBAAQiCYAgEA0AQAET0UZG/4Q5EChAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model_22 (Model)             (None, 32, 32, 3)         16513103  \n",
      "_________________________________________________________________\n",
      "model_23 (Model)             (None, 1)                 11685889  \n",
      "=================================================================\n",
      "Total params: 28,198,992\n",
      "Trainable params: 27,885,092\n",
      "Non-trainable params: 313,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build stacked GAN model\n",
    "gan_input = Input(shape=[100])\n",
    "H = generator.model(gan_input)\n",
    "gan_V = discriminator.model(H)\n",
    "GAN = Model(gan_input, gan_V)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(), metics = ['binary_crossentropy'])\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PImage\n",
    "from os import listdir\n",
    "import scipy.misc\n",
    "def loadImages(path):\n",
    "    # return array of images\n",
    "\n",
    "    imagesList = listdir(path)\n",
    "   \n",
    "    loadedImages = []\n",
    "    for image in imagesList:\n",
    "        if image != '.DS_Store':\n",
    "            img = cv2.imread(path + image)\n",
    "            loadedImages.append(img.copy())\n",
    "            img.load()\n",
    "            img.close()\n",
    "            \n",
    "    return loadedImages\n",
    "\n",
    "path = \"/Users/nickstepanov/GAN/EmojiOne/\"\n",
    "\n",
    "# your images in an array\n",
    "def real_imgs():\n",
    "    imgs = loadImages(path)\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for img in imgs:\n",
    "        # you can show every image\n",
    "        print(img[0])\n",
    "        pix = scipy.misc.imresize(np.array(img.getdata()).reshape(img.size[0], img.size[1], 3),(32,32))\n",
    "        X_train.append(pix)\n",
    "        Y_train.append(1)\n",
    "    X_train = np.array(X_train)\n",
    "    X_train = X_train/255.\n",
    "    Y_train = np.array(Y_train)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Discriminator on True dataset\n",
    "def train_disc(X,Y,epochs=5):\n",
    "    while epochs>0:\n",
    "        print (\"Epochs on discriminator left: %d \"%(epochs))\n",
    "        discriminator.model.fit(X,Y, batch_size=32)\n",
    "        epochs = epochs - 1\n",
    "def disc_pred(X):\n",
    "    return discriminator.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Fake dataset\n",
    "def gen_fake():\n",
    "    X_fake = []\n",
    "    Y_fake = []\n",
    "    numP = 10\n",
    "    img = generator.forward(np.random.uniform(0,1,size=[numP,100]))\n",
    "    X_fake = np.array(img)\n",
    "    X_fake = X_fake/255.\n",
    "\n",
    "    for i in range(numP):\n",
    "        Y_fake.append(0)\n",
    "    return np.array(X_fake), np.array(Y_fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X,Y):\n",
    "    y_hat = discriminator.forward(X)\n",
    "    y_hat_idx = np.argmax(y_hat,axis=1)\n",
    "    y_idx = np.argmax(Y,axis=0)\n",
    "    diff = y_idx-y_hat_idx\n",
    "    n_tot = X_train.shape[0]\n",
    "    n_rig = (diff==0).sum()\n",
    "    acc = n_rig*100.0/n_tot\n",
    "    print (\"Accuracy: %0.02f pct (%d of %d) right\"%(acc, n_rig, n_tot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze weights in the discriminator for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.model.layers:\n",
    "        l.trainable = val\n",
    "    net.model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam())\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      "Generate fake imgs\n",
      "Train on fake imgs\n",
      "Epochs on discriminator left: 5 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 2s - loss: 15.9424\n",
      "Epochs on discriminator left: 4 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 0s - loss: 15.9424\n",
      "Epochs on discriminator left: 3 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 0s - loss: 15.9424\n",
      "Epochs on discriminator left: 2 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 0s - loss: 15.9424\n",
      "Epochs on discriminator left: 1 \n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 0s - loss: 15.9424\n",
      "Train on real imgs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-68ca7048f97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-68ca7048f97c>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m        \u001b[0mtrain_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train on real imgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m        \u001b[0mtrain_disc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m        \u001b[0mnoise_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1028\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-a73af870df88>\u001b[0m in \u001b[0;36mreal_imgs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# your images in an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreal_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-a73af870df88>\u001b[0m in \u001b[0;36mloadImages\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimagesList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloadedImages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    " # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "def plot_loss(losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(losses[\"d\"], label='discriminitive loss_a')\n",
    "    plt.plot(losses[\"r\"], label='discriminitive loss_b')\n",
    "    plt.plot(losses[\"g\"], label='generative loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def train_gan(epochs=5):\n",
    "    losses = {\"d\":[], \"g\":[], \"r\":[]}\n",
    "    for i in range(epochs):\n",
    "        print (\"Epoch: %d \"%(i))\n",
    "        make_trainable(discriminator,True)\n",
    "        print(\"Generate fake imgs\")\n",
    "        X, Y = gen_fake()\n",
    "        print(\"Train on fake imgs\")\n",
    "        train_disc(X,Y)\n",
    "        print(\"Train on real imgs\")\n",
    "        X, Y = real_imgs()\n",
    "        train_disc(X,Y)\n",
    "        noise_tr = np.random.uniform(0,1,size=[1028,100])\n",
    "        y2 = np.zeros([1028,1])\n",
    "        #y2 = discriminator.forward(generator.forward(noise_tr))   \n",
    "        y2 = np.array([1] * 1028)\n",
    "        make_trainable(discriminator,False)\n",
    "        callback = keras.callbacks.ProgbarLogger(count_mode='samples')\n",
    "        g_loss = GAN.fit_generator(noise_tr, y2 , epochs = 5, verbose = 1,callbacks = callback)\n",
    "        losses[\"g\"].append(g_loss)\n",
    "        plot_gen()\n",
    "    plot_loss(losses)\n",
    "    \n",
    "\n",
    "\n",
    "train_gan(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 0.00196188,  0.00196006,  0.00195882],\n",
       "          [ 0.00196257,  0.00195939,  0.00196116],\n",
       "          [ 0.00196152,  0.00195709,  0.0019609 ],\n",
       "          ..., \n",
       "          [ 0.0019633 ,  0.00196031,  0.00195812],\n",
       "          [ 0.00196186,  0.00196018,  0.00195877],\n",
       "          [ 0.00196029,  0.00196143,  0.00195994]],\n",
       " \n",
       "         [[ 0.0019622 ,  0.00196036,  0.00196005],\n",
       "          [ 0.00195912,  0.00195944,  0.00195943],\n",
       "          [ 0.00196041,  0.00195847,  0.00195802],\n",
       "          ..., \n",
       "          [ 0.00196191,  0.00195654,  0.00196095],\n",
       "          [ 0.00196233,  0.00195699,  0.00195856],\n",
       "          [ 0.00196148,  0.00195916,  0.00195797]],\n",
       " \n",
       "         [[ 0.00195956,  0.00196007,  0.00195865],\n",
       "          [ 0.00195984,  0.00195742,  0.0019584 ],\n",
       "          [ 0.0019597 ,  0.00195861,  0.00196145],\n",
       "          ..., \n",
       "          [ 0.00196332,  0.00195772,  0.00195865],\n",
       "          [ 0.00196184,  0.00195781,  0.00196028],\n",
       "          [ 0.00196033,  0.00195959,  0.00195999]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196062,  0.00196068,  0.00195983],\n",
       "          [ 0.00195854,  0.00195446,  0.00195597],\n",
       "          [ 0.00196231,  0.00195872,  0.00195984],\n",
       "          ..., \n",
       "          [ 0.0019622 ,  0.00195947,  0.00196205],\n",
       "          [ 0.00195811,  0.00195843,  0.00195847],\n",
       "          [ 0.00196155,  0.00196051,  0.00196053]],\n",
       " \n",
       "         [[ 0.00196127,  0.00196033,  0.00195945],\n",
       "          [ 0.00196226,  0.00196005,  0.00196007],\n",
       "          [ 0.00195942,  0.00195779,  0.00196207],\n",
       "          ..., \n",
       "          [ 0.00195793,  0.00195574,  0.00196128],\n",
       "          [ 0.00196138,  0.00195944,  0.00196079],\n",
       "          [ 0.00195984,  0.0019597 ,  0.00195777]],\n",
       " \n",
       "         [[ 0.00196073,  0.00195987,  0.00195989],\n",
       "          [ 0.00196362,  0.00196004,  0.00196085],\n",
       "          [ 0.00196288,  0.0019605 ,  0.0019615 ],\n",
       "          ..., \n",
       "          [ 0.0019589 ,  0.00195955,  0.0019605 ],\n",
       "          [ 0.00196187,  0.00195977,  0.00196056],\n",
       "          [ 0.00196177,  0.00196004,  0.00196017]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00196078,  0.00195955,  0.00195939],\n",
       "          [ 0.00196237,  0.00195826,  0.0019611 ],\n",
       "          [ 0.00196025,  0.00195864,  0.00196046],\n",
       "          ..., \n",
       "          [ 0.00196259,  0.00196086,  0.00195931],\n",
       "          [ 0.00196081,  0.00195847,  0.00196005],\n",
       "          [ 0.00196061,  0.00195962,  0.0019595 ]],\n",
       " \n",
       "         [[ 0.00196049,  0.00196039,  0.0019593 ],\n",
       "          [ 0.00195669,  0.00195727,  0.00195916],\n",
       "          [ 0.00196086,  0.0019592 ,  0.00195917],\n",
       "          ..., \n",
       "          [ 0.00196045,  0.00195855,  0.00195971],\n",
       "          [ 0.00196101,  0.0019584 ,  0.00196029],\n",
       "          [ 0.00196002,  0.00195959,  0.00195929]],\n",
       " \n",
       "         [[ 0.00196085,  0.00195951,  0.00195884],\n",
       "          [ 0.00195881,  0.00195801,  0.00196104],\n",
       "          [ 0.00195879,  0.00195765,  0.00196131],\n",
       "          ..., \n",
       "          [ 0.00196368,  0.00195696,  0.00196016],\n",
       "          [ 0.00195866,  0.00195781,  0.00195891],\n",
       "          [ 0.0019603 ,  0.00195902,  0.00196094]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.0019603 ,  0.00195913,  0.00196011],\n",
       "          [ 0.00196098,  0.00195755,  0.00195725],\n",
       "          [ 0.00195956,  0.00195883,  0.0019591 ],\n",
       "          ..., \n",
       "          [ 0.00196089,  0.00195917,  0.00196089],\n",
       "          [ 0.00195897,  0.00195999,  0.00195948],\n",
       "          [ 0.00196144,  0.0019598 ,  0.001958  ]],\n",
       " \n",
       "         [[ 0.0019617 ,  0.00196007,  0.00195972],\n",
       "          [ 0.00196076,  0.00196042,  0.00195864],\n",
       "          [ 0.00196008,  0.00195631,  0.00196134],\n",
       "          ..., \n",
       "          [ 0.00195952,  0.00195672,  0.00196   ],\n",
       "          [ 0.00196361,  0.00195974,  0.00196151],\n",
       "          [ 0.00196059,  0.00196013,  0.00195819]],\n",
       " \n",
       "         [[ 0.00196175,  0.00196194,  0.00195973],\n",
       "          [ 0.00196055,  0.00195858,  0.00196136],\n",
       "          [ 0.00196177,  0.00195995,  0.001962  ],\n",
       "          ..., \n",
       "          [ 0.00195913,  0.0019607 ,  0.00196031],\n",
       "          [ 0.00196322,  0.00196094,  0.00196153],\n",
       "          [ 0.00196079,  0.00195984,  0.00196   ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00196188,  0.00195995,  0.00195976],\n",
       "          [ 0.00196237,  0.00195876,  0.00196145],\n",
       "          [ 0.00196274,  0.00195859,  0.00196095],\n",
       "          ..., \n",
       "          [ 0.0019606 ,  0.00195934,  0.00195861],\n",
       "          [ 0.00196198,  0.00196059,  0.00196067],\n",
       "          [ 0.00196173,  0.00196084,  0.00195979]],\n",
       " \n",
       "         [[ 0.00196251,  0.00195927,  0.00196125],\n",
       "          [ 0.00195773,  0.00195712,  0.00196026],\n",
       "          [ 0.00196187,  0.00195973,  0.00195828],\n",
       "          ..., \n",
       "          [ 0.00196067,  0.00195783,  0.00195909],\n",
       "          [ 0.00196207,  0.0019581 ,  0.00195846],\n",
       "          [ 0.00196159,  0.00196002,  0.00195832]],\n",
       " \n",
       "         [[ 0.00196168,  0.00195929,  0.00195924],\n",
       "          [ 0.00195973,  0.00195681,  0.00195976],\n",
       "          [ 0.00195878,  0.00195799,  0.00196101],\n",
       "          ..., \n",
       "          [ 0.0019614 ,  0.00195847,  0.00195928],\n",
       "          [ 0.00196056,  0.00195914,  0.00195986],\n",
       "          [ 0.00195989,  0.00195867,  0.00195946]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196109,  0.00196024,  0.00195924],\n",
       "          [ 0.00196294,  0.00195775,  0.00195612],\n",
       "          [ 0.00196308,  0.00195977,  0.00196065],\n",
       "          ..., \n",
       "          [ 0.00196044,  0.00195771,  0.00196097],\n",
       "          [ 0.00196029,  0.00195888,  0.00195858],\n",
       "          [ 0.00196009,  0.00195843,  0.00195798]],\n",
       " \n",
       "         [[ 0.00196196,  0.0019603 ,  0.00195919],\n",
       "          [ 0.00196061,  0.00195784,  0.00195725],\n",
       "          [ 0.00196077,  0.0019582 ,  0.00195975],\n",
       "          ..., \n",
       "          [ 0.00195909,  0.0019551 ,  0.00196136],\n",
       "          [ 0.00196512,  0.00196049,  0.00196051],\n",
       "          [ 0.00196005,  0.00196031,  0.00195894]],\n",
       " \n",
       "         [[ 0.00196305,  0.00196257,  0.00195866],\n",
       "          [ 0.00196319,  0.0019594 ,  0.00196129],\n",
       "          [ 0.00196274,  0.00196146,  0.00196186],\n",
       "          ..., \n",
       "          [ 0.00195944,  0.00196062,  0.0019595 ],\n",
       "          [ 0.00196224,  0.00196039,  0.00196232],\n",
       "          [ 0.00196129,  0.00195883,  0.00196056]]],\n",
       " \n",
       " \n",
       "        ..., \n",
       "        [[[ 0.00196138,  0.00195966,  0.00195881],\n",
       "          [ 0.00196248,  0.00195876,  0.0019617 ],\n",
       "          [ 0.0019627 ,  0.00195998,  0.00196147],\n",
       "          ..., \n",
       "          [ 0.00196217,  0.0019606 ,  0.00195968],\n",
       "          [ 0.00196089,  0.00195848,  0.00195978],\n",
       "          [ 0.00196234,  0.00196052,  0.00196067]],\n",
       " \n",
       "         [[ 0.00196157,  0.00196031,  0.00195973],\n",
       "          [ 0.00195746,  0.0019585 ,  0.00195936],\n",
       "          [ 0.001961  ,  0.00195891,  0.00195754],\n",
       "          ..., \n",
       "          [ 0.00196198,  0.00195764,  0.00196193],\n",
       "          [ 0.00196277,  0.00195714,  0.00196017],\n",
       "          [ 0.00196049,  0.00195847,  0.00195941]],\n",
       " \n",
       "         [[ 0.00196099,  0.00195956,  0.00195871],\n",
       "          [ 0.00196012,  0.00195737,  0.00196042],\n",
       "          [ 0.00196004,  0.00195589,  0.00196219],\n",
       "          ..., \n",
       "          [ 0.00196272,  0.00195842,  0.00195887],\n",
       "          [ 0.00195997,  0.00195876,  0.00196014],\n",
       "          [ 0.00196076,  0.00196021,  0.00195919]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196032,  0.00195976,  0.00195981],\n",
       "          [ 0.0019607 ,  0.00195529,  0.00195759],\n",
       "          [ 0.00195993,  0.00195984,  0.0019592 ],\n",
       "          ..., \n",
       "          [ 0.00196095,  0.0019587 ,  0.00196148],\n",
       "          [ 0.00195724,  0.00195725,  0.00195746],\n",
       "          [ 0.00196073,  0.00195954,  0.00195952]],\n",
       " \n",
       "         [[ 0.00196057,  0.0019602 ,  0.0019597 ],\n",
       "          [ 0.00196119,  0.0019592 ,  0.00196021],\n",
       "          [ 0.00196002,  0.00195763,  0.00196268],\n",
       "          ..., \n",
       "          [ 0.00196034,  0.00195846,  0.00196178],\n",
       "          [ 0.00196442,  0.00195968,  0.00196114],\n",
       "          [ 0.00196069,  0.00195996,  0.00195898]],\n",
       " \n",
       "         [[ 0.00196211,  0.00196203,  0.00196001],\n",
       "          [ 0.00196069,  0.00195827,  0.00196139],\n",
       "          [ 0.00196049,  0.00196089,  0.00196216],\n",
       "          ..., \n",
       "          [ 0.00195926,  0.00196039,  0.00196094],\n",
       "          [ 0.00196261,  0.00196028,  0.00196103],\n",
       "          [ 0.00196139,  0.00195928,  0.00196048]]],\n",
       " \n",
       " \n",
       "        [[[ 0.001962  ,  0.00196024,  0.00195861],\n",
       "          [ 0.0019613 ,  0.00195954,  0.00195972],\n",
       "          [ 0.00196273,  0.00195945,  0.0019613 ],\n",
       "          ..., \n",
       "          [ 0.00196294,  0.00196045,  0.00195883],\n",
       "          [ 0.0019625 ,  0.00195778,  0.00196128],\n",
       "          [ 0.00196162,  0.00196062,  0.00196004]],\n",
       " \n",
       "         [[ 0.00196076,  0.00196016,  0.00195935],\n",
       "          [ 0.00195882,  0.00195762,  0.00195948],\n",
       "          [ 0.00196101,  0.00195894,  0.00195898],\n",
       "          ..., \n",
       "          [ 0.00196124,  0.00195701,  0.0019624 ],\n",
       "          [ 0.00196139,  0.00195728,  0.00195983],\n",
       "          [ 0.00196129,  0.00195996,  0.00195858]],\n",
       " \n",
       "         [[ 0.00195985,  0.00196009,  0.00195978],\n",
       "          [ 0.0019599 ,  0.00195745,  0.00196035],\n",
       "          [ 0.00195823,  0.00195838,  0.0019615 ],\n",
       "          ..., \n",
       "          [ 0.00196506,  0.00195962,  0.00196087],\n",
       "          [ 0.00196249,  0.00195826,  0.00195997],\n",
       "          [ 0.00195954,  0.00195907,  0.00196059]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196071,  0.00196033,  0.00196033],\n",
       "          [ 0.00195857,  0.00195531,  0.00195684],\n",
       "          [ 0.00196255,  0.00195909,  0.00196133],\n",
       "          ..., \n",
       "          [ 0.00196188,  0.00195935,  0.00196169],\n",
       "          [ 0.0019591 ,  0.00195788,  0.00196016],\n",
       "          [ 0.00196019,  0.00195844,  0.0019596 ]],\n",
       " \n",
       "         [[ 0.00196172,  0.00196085,  0.00195927],\n",
       "          [ 0.00195988,  0.00195998,  0.00195983],\n",
       "          [ 0.00196101,  0.00195785,  0.00196214],\n",
       "          ..., \n",
       "          [ 0.00195919,  0.00195691,  0.00196118],\n",
       "          [ 0.00196131,  0.00195906,  0.0019606 ],\n",
       "          [ 0.00196048,  0.00196084,  0.00196049]],\n",
       " \n",
       "         [[ 0.00196033,  0.00196117,  0.00195896],\n",
       "          [ 0.00196203,  0.00196032,  0.00196041],\n",
       "          [ 0.00196175,  0.00196069,  0.00196122],\n",
       "          ..., \n",
       "          [ 0.00196016,  0.00195983,  0.00196112],\n",
       "          [ 0.00196295,  0.00196081,  0.00196159],\n",
       "          [ 0.00196211,  0.00196015,  0.00196105]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00196118,  0.00196002,  0.0019591 ],\n",
       "          [ 0.00196178,  0.00195867,  0.00196119],\n",
       "          [ 0.00196188,  0.0019604 ,  0.00196   ],\n",
       "          ..., \n",
       "          [ 0.0019627 ,  0.00196102,  0.00195988],\n",
       "          [ 0.00196104,  0.00195821,  0.00195975],\n",
       "          [ 0.00196154,  0.00195998,  0.00196003]],\n",
       " \n",
       "         [[ 0.00196165,  0.0019601 ,  0.00195976],\n",
       "          [ 0.0019576 ,  0.00195829,  0.00195907],\n",
       "          [ 0.00196049,  0.00195836,  0.00195916],\n",
       "          ..., \n",
       "          [ 0.00196066,  0.00195861,  0.00195862],\n",
       "          [ 0.00196144,  0.00195657,  0.00195905],\n",
       "          [ 0.00196049,  0.00195947,  0.00196014]],\n",
       " \n",
       "         [[ 0.00196062,  0.00195962,  0.00195943],\n",
       "          [ 0.00196024,  0.00195887,  0.00195952],\n",
       "          [ 0.00196031,  0.00195864,  0.00196104],\n",
       "          ..., \n",
       "          [ 0.00196392,  0.00195915,  0.00195979],\n",
       "          [ 0.00196127,  0.00195883,  0.00195907],\n",
       "          [ 0.00195914,  0.00195933,  0.00195987]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.00196074,  0.00196007,  0.00196015],\n",
       "          [ 0.00195919,  0.00195838,  0.00195682],\n",
       "          [ 0.00196017,  0.00195854,  0.00195917],\n",
       "          ..., \n",
       "          [ 0.00196115,  0.0019582 ,  0.00196032],\n",
       "          [ 0.0019604 ,  0.00195741,  0.00196032],\n",
       "          [ 0.00196048,  0.00195907,  0.00195983]],\n",
       " \n",
       "         [[ 0.00196168,  0.00196007,  0.00196011],\n",
       "          [ 0.00196114,  0.00195843,  0.0019599 ],\n",
       "          [ 0.00195877,  0.00195654,  0.00196076],\n",
       "          ..., \n",
       "          [ 0.00195952,  0.00195792,  0.00196029],\n",
       "          [ 0.00196336,  0.001959  ,  0.00196121],\n",
       "          [ 0.00196064,  0.00196092,  0.00195966]],\n",
       " \n",
       "         [[ 0.00196102,  0.00196135,  0.00196   ],\n",
       "          [ 0.00196281,  0.00195895,  0.00196044],\n",
       "          [ 0.00196245,  0.00195922,  0.00196215],\n",
       "          ..., \n",
       "          [ 0.00196022,  0.00196085,  0.0019608 ],\n",
       "          [ 0.00196163,  0.00196035,  0.00196103],\n",
       "          [ 0.00196199,  0.00196051,  0.00196049]]]], dtype=float32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_fake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
